---
title: "PROVE-IT multiple logistic regression, complete case analysis"
author: "SCS Rivrud, RJ Eck, ERH Heijkoop"
output:
  html_document:
    code_folding: hide
---
**Load packages**
```{r message=FALSE, warning=FALSE}
library(rms)
library(glmnet)
library(pec)
library(Hmisc)
library(qreport)
library(DescTools)
library(e1071)
library(ggpubr)
library(bestNormalize)
library(GGally)
library(broom)
library(MASS)
library(adjustedCurves)
library(pROC)
library(rsample)
library(riskRegression)
library(here)
library(RSQLite)
library(gridExtra)
library(kableExtra)
library(grid)
library(janitor)
library(miceafter)
library(gtsummary)
library(flextable)
library(grid)
library(forestploter)
library(tidyverse)
library(patchwork)
library(dcurves)
library(epiDisplay)

#remotes::install_github("gweissman/gmish")
library(gmish)

``` 

**Select predictors and set seed**
```{r message=FALSE, warning=FALSE, eval=FALSE}
#variables from Tran et al: DOI: 10.1097/CCM.0000000000005382 
set.seed(42)

#the two sig prognostic factors with the largest OR
fixed_vars <- c("cvl","previousvte", "malignancy", "median_temp", "rr_median", "lactate", "wbc", "surgical_30_days", "vasoactives","mech_vent", "anticoag_proph_24", "weight", "median_heart_rate", "median_bp_map")

fixed_vars_coded <- c("cvl1","previousvte1", "malignancy1", "median_temp", "rr_median", "lactate", "wbc", "surgical_30_days1", "vasoactives1","mech_vent1", "anticoag_proph_241", "weight", "median_heart_rate", "median_bp_map")

#all significant prognostic factors from the meta analysis, except sepsis, as susepcted infection cannot determined for every patient. Sepsis is replaced by parameters used in the definition of SEPSIS III

#https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4968574/ SEPSIS III definition
```

**Loading and prepping development set**
```{r, eval=FALSE}
#specify relative path

mimic <- readRDS("analysis subsets/complete_mimic.RDS")

mimic <- mimic %>%
  mutate(rr_median = first_rr_median,
         cvl = as.factor(cvl),
         sex = as.factor(
           case_when(
             sex == "M" ~ 1,
             TRUE ~ 0
           )),
         rr_median = rr_median/5,
         lactate = lactate,
         wbc = wbc/5,
         weight = weight/10,
         median_bp_map = median_bp_map/10,
         median_heart_rate = median_heart_rate/10
         ) %>%
    select(all_of(c("subject_id","status_dich", fixed_vars))) %>%
    mutate(across(c("malignancy", "cvl", "previousvte", "surgical_30_days", 
                  "mech_vent", "vasoactives", "anticoag_proph_24"),
                ~as.numeric(as.character(.)),
                .names = "{.col}1")
           ) %>%
  na.omit()


```

**Loading and prepping external validation set**
```{r, eval=FALSE}
sics <- readRDS("analysis subsets/sics_full.rds") %>%
  mutate(
    median_bp_map = case_when(
    is.na(median_bp_map) ~ first_bp_map,
    TRUE ~ median_bp_map
  ),
    rr_median = case_when(
    is.na(rr_median) ~ first_rr,
    TRUE ~ rr_median),
  
    median_heart_rate = case_when(
    is.na(median_heart_rate) ~ first_heart_rate,
    TRUE ~ median_heart_rate),
     cvl = as.factor(cvl)
  )%>%
    select(all_of(c("status_dich",fixed_vars))) 

bb <- readRDS("analysis subsets/biobank_full.rds")%>%
  mutate(median_temp = median_temp,
         status_dich = as.numeric(as.character(status_dich))
         ) %>% #temporary until i get updated temp file
    select(all_of(c("status_dich", fixed_vars))) 

sics_bb <- rbind.data.frame(sics, bb) %>%
  mutate(
     subject_id = as.character(row_number()),
     rr_median = rr_median/5,
     wbc = wbc/5,
     weight = weight/10,
     median_bp_map = median_bp_map/10,
     median_heart_rate = median_heart_rate/10
  ) %>%
      select(all_of(c("subject_id", "status_dich", fixed_vars))) %>%
    mutate(across(c("malignancy", "cvl", "previousvte", "surgical_30_days", 
                  "mech_vent", "vasoactives", "anticoag_proph_24"),
                ~as.numeric(as.character(.)),
                .names = "{.col}1")
           ) %>%
  na.omit()
```

**Fit logistic regression model and make summary tables and graphs to illustrate Odds ratios**
```{r, eval=FALSE}
options(scipen = 999, digits = 4)

cc_model <- glm(
   status_dich ~ cvl + previousvte + malignancy + median_temp + rr_median + lactate + wbc + surgical_30_days + vasoactives + mech_vent + anticoag_proph_24 + weight + median_heart_rate + median_bp_map, family = binomial(link = 'logit'), data = mimic)

or_model <- cc_model %>%
  summary(conf.int = TRUE)

or_model <- or_model$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "term")

or_model <- or_model %>%
  mutate(or = exp(Estimate),
  term = case_when(
    term == "rr_median" ~ "Respiratory rate per 5 unit increase",
    term == "median_bp_map" ~ "Mean arterial blood pressure per 10 mmHg increase",
    term == "lactate" ~ "Lactate per 1 mmol/L increase",
    term == "weight" ~ "Weight per 10 kg increase",
    term == "wbc" ~ "White blood cell count per 5 K/uL increase",
    term == "age" ~ "Age per 10 year increase",
    term == "median_heart_rate" ~ "Heart rate per 10 bpm increase",
    term == "vasoactives1" ~ "Vasopressors within 24 hours of ICU admission",
    term == "mech_vent1" ~ "Mechanical ventilation within 24 hours of ICU admission",
    term == "malignancy1" ~ "Active malignancy",
    term == "surgical_30_days1" ~ "Surgical ICU admission",
    term == "previousvte1" ~ "Personal history of VTE",
    term == "cvl1" ~ "Central venous line within 24 hours of ICU admission",
    term == "(Intercept)" ~ "Intercept",
    term == "anticoag_proph_241" ~ "Thromboprophylaxis within 24 hours of ICU admission",
    term == "median_temp" ~ "Body temperature per 1°C increase",
    TRUE ~ term
  ),
    lower_ci = exp(Estimate - `Std. Error`*1.96),
    upper_ci = exp(Estimate + `Std. Error`*1.96),
          `p-value`  = signif(`Pr(>|z|)`, digits = 3),
         or = signif(or, digits = 3),
         lower_ci = signif(lower_ci, digits = 3),
         upper_ci = signif(upper_ci, digits = 3)) %>%
  select(term, or, lower_ci, upper_ci, `p-value`)

or_print <- or_model %>%
    filter(!grepl("Intercept", term)) %>%
  mutate(`95% CI` = paste0("(", signif(as.numeric(lower_ci), digits = 3), ", ", signif(as.numeric(upper_ci), digits = 3), ")")) %>%
    select(Term = term, OR = or,`95% CI`, `p-value` )%>%
  kbl("html", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Times")


odds_ratios_continuous <- or_model %>%
  filter(term != "Intercept" & 
           (grepl("White blood cell count per 5 K/uL increase", term, ignore.case = TRUE) |
            grepl("Heart rate per 10 bpm increase", term, ignore.case = TRUE) |
            grepl("Body temperature per 1°C increase", term, ignore.case = TRUE) |
            grepl("Age per 10 year increase", term, ignore.case = TRUE) |            
            grepl("Weight per 10 kg increase", term, ignore.case = TRUE) |            
            grepl("Respiratory rate per 5 unit increase", term, ignore.case = TRUE) |            
            grepl("Lactate per 1 mmol/L increase", term, ignore.case = TRUE)        |
            grepl("Mean arterial blood pressure per 10 mmHg increase", term, ignore.case = TRUE)             
              )) 

odds_ratios_categorical <- or_model %>%
  filter(term != "Intercept" & 
           (!grepl("White blood cell count per 5 K/uL increase", term, ignore.case = TRUE) &
            !grepl("Heart rate per 10 bpm increase", term, ignore.case = TRUE) &
            !grepl("Body temperature per 1°C increase", term, ignore.case = TRUE) &
            !grepl("Age per 10 year increase", term, ignore.case = TRUE) &            
            !grepl("Weight per 10 kg increase", term, ignore.case = TRUE) &           
            !grepl("Respiratory rate per 5 unit increase", term, ignore.case = TRUE) &            
            !grepl("Lactate per 1 mmol/L increase", term, ignore.case = TRUE)        &
            !grepl("Mean arterial blood pressure per 10 mmHg increase", term, ignore.case = TRUE)             
              )) 

#continuous predictors plot
odds_ratios_plot_continuous <- ggplot(odds_ratios_continuous, aes(x = term, y = or)) +
  geom_point(shape = 15) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.4, size = 0.5, color = "black") + #95% CI
  geom_hline(yintercept = 1, linetype = "dotted", color = "darkred") +
  coord_flip() + 
  ylab("OR") +
  xlab("Continuous predictors") +
   scale_y_continuous(breaks = seq(0.25, 1.75, by = 0.5), limits = c(0.25, 1.75)) + #set y-axis breaks
  ylim(0.25, 1.75) +
  theme_bw() +
  theme(text = element_text(family = "Times New Roman"), #set font to Times New Roman
        plot.title = element_text(hjust = 0.5),
        axis.title.y = element_text(face = "italic", size = 10)) 

#categorical predictors plot
odds_ratios_plot_categorical <- ggplot(odds_ratios_categorical, aes(x = term, y = or)) +
  geom_point(shape = 15) +
  geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.4, size = 0.5, color = "black") + #95% CI
  geom_hline(yintercept = 1, linetype = "dotted", color = "darkred") +
  coord_flip() + 
  ylab("OR") +
  xlab("Binary predictors") +
   scale_y_continuous(breaks = seq(-1.5, 3.5, by = 0.5), limits = c(-1.5, 4)) + #set y-axis breaks
  theme_bw()  +
  theme(text = element_text(family = "Times New Roman"), #set font to Times New Roman
        plot.title = element_text(hjust = 0.5),
        axis.title.y = element_text(face = "italic", size = 10, family = "Times New Roman")) 

stacked_plots <- odds_ratios_plot_continuous / odds_ratios_plot_categorical +
  plot_annotation(
    title = expression(bold("Figure x.") ~ "Odds ratios for continuous and binary predictors"),
    theme = theme(
      plot.title = element_text(hjust = 0.5, size = 12),
      text = element_text(family = "Times New Roman"), #set font to Times New Roman
    )
  )
```

**Extract log odds coefficients from pooled fit to use for calibration plots and external validation**
```{r, eval=FALSE}
#make df with coefficients
coefficients <- cc_model %>%
  summary(conf.int = TRUE)

coefficients <- coefficients$coefficients %>%
  as.data.frame() %>%
  rownames_to_column(var = "term") %>%
  rename(estimate = Estimate)

#initialize an empty coefficient list 
coefficients_list <- list()

#iterate over candidate variables to extract coefficients
for (var in fixed_vars_coded) {
  coefficients_list[[var]] <- if(var %in% coefficients$term) {
    coefficients$estimate[coefficients$term == var]
  } else {
    0 #default coefficient if the variable is not found (wont happen really )
  }
}
```

**Boostrap function for internal validation**
```{r, eval=FALSE}
#define bootstrap function
bootstrap_validation_logreg <- function(data, n_bootstrap) {
  
  #make storage for apparent values (original model tested on bootstrap dataset)
  auc_values_apparent <- numeric(n_bootstrap)
  brier_score_apparent <- numeric(n_bootstrap) 
  emax_apparent <- numeric(n_bootstrap)
  e50_apparent <- numeric(n_bootstrap)
  e90_apparent <- numeric(n_bootstrap)
  r2_apparent <- numeric(n_bootstrap)
  aic_apparent <- numeric(n_bootstrap)
  ici_apparent <- numeric(n_bootstrap)

  #make storage for original values (bootstrap model tested on original dataset)
  auc_values_corrected <- numeric(n_bootstrap)
  brier_score_corrected <- numeric(n_bootstrap) 
  emax_corrected <- numeric(n_bootstrap)
  e50_corrected <- numeric(n_bootstrap)
  e90_corrected <- numeric(n_bootstrap)
  r2_corrected <- numeric(n_bootstrap)
  ici_corrected <- numeric(n_bootstrap)
  
  
  for(i in 1:n_bootstrap) {
    #resampling indices
    bootstrap_data <- sample_n(data, nrow(data), replace = TRUE)

    #predict on the bootstrap sample
  model_full <- glm(status_dich ~ cvl + previousvte + malignancy + median_temp + rr_median + lactate + wbc + surgical_30_days + vasoactives + mech_vent + anticoag_proph_24 + weight + median_heart_rate + median_bp_map, data = data, family = binomial(link = 'logit'))

    #fit model on boot data
    model_boot <- glm(status_dich ~ cvl + previousvte + malignancy + median_temp + rr_median + lactate + wbc + surgical_30_days + vasoactives + mech_vent + anticoag_proph_24 + weight + median_heart_rate + median_bp_map, data = bootstrap_data, family = binomial(link = 'logit'))
    
    #calculate apparent discrimination
    data_prob_vte <- predict(model_full, type = "response") 
    apparent_cal <- val.prob(data_prob_vte, data$status_dich, pl = FALSE)
    
    #store apparent values
    auc_result_apparent <- roc(data$status_dich, data_prob_vte, ci = TRUE, direction = "<")
    vec_sd_auc_values_apparent <- ((auc_result_apparent$ci[3] - auc_result_apparent$auc) / 1.96)*sqrt(length(data$status_dich))
    e50_ap <- unname(quantile(abs(data_prob_vte - approx(lowess(data_prob_vte, data$status_dich, iter=0), xout=data_prob_vte, ties=mean)$y), 0.5))
    
    #store bootstrapped values
    boot_prob_vte <- predict(model_boot, type = "response")
    boot_cal <- val.prob(boot_prob_vte, bootstrap_data$status_dich, pl = FALSE)
    auc_boot <- roc(bootstrap_data$status_dich, boot_prob_vte, ci = TRUE, direction = "<")
    auc_values_boot <- auc_boot$auc
    e50_boot <- unname(quantile(abs(boot_prob_vte - approx(lowess(boot_prob_vte, bootstrap_data$status_dich, iter=0), xout=boot_prob_vte, ties=mean)$y), 0.5))

    #store original values
    orig_prob_vte <- predict(model_boot, newdata = data, type = "response")
    orig_cal <- val.prob(orig_prob_vte,data$status_dich, pl = FALSE)
    auc_original <- roc(data$status_dich, orig_prob_vte, ci = TRUE, direction = "<")
    auc_values_original <- auc_original$auc
    e50_orig <- unname(quantile(abs(orig_prob_vte - approx(lowess(orig_prob_vte, data$status_dich, iter=0), xout=orig_prob_vte, ties=mean)$y), 0.5))

    #calculate the corrected score
    auc_values_corrected[i] <- (auc_result_apparent$auc) - abs(auc_values_boot - auc_values_original)
    brier_score_corrected[i] <- mean((data_prob_vte - as.numeric(data$status_dich))^2) + abs(mean((boot_prob_vte - bootstrap_data$status_dich)^2) - mean((orig_prob_vte - data$status_dich)^2))
    emax_corrected[i] <- apparent_cal[[14]] + abs(boot_cal[[14]]  - orig_cal[[14]])
    ici_corrected[i] <- apparent_cal[[16]] + abs(boot_cal[[16]]  - orig_cal[[16]])
    e90_corrected[i] <- apparent_cal[[15]] + abs(boot_cal[[15]]  - orig_cal[[15]])
    r2_corrected[i] <- apparent_cal[[3]] - abs(boot_cal[[3]]  - orig_cal[[3]])
    e50_corrected[i] <- e50_ap + abs(e50_boot - e50_orig)

    #calculate apparent score
    auc_values_apparent[i] <- auc_result_apparent$auc
    brier_score_apparent[i] <- mean((data_prob_vte - as.numeric(data$status_dich))^2)
    emax_apparent[i] <- apparent_cal[[14]]
    ici_apparent[i] <- apparent_cal[[16]]
    e90_apparent[i] <- apparent_cal[[15]] 
    r2_apparent[i] <- apparent_cal[[3]] 
    aic_apparent[i] <- model_full$aic
    e50_apparent[i] <- e50_ap
  }
  
  #pooling the results directly in the function
  auc_df <- data.frame(
    auc_apparent = auc_values_apparent,
    brier_score_apparent = brier_score_apparent,
    emax_apparent = emax_apparent,
    e50_apparent = e50_apparent,
    e90_apparent = e90_apparent,
    r2_apparent = r2_apparent,
    aic_apparent = aic_apparent,
    ici_apparent = ici_apparent,
    
    auc_corrected = auc_values_corrected,
    brier_score_corrected = brier_score_corrected,
    emax_corrected = emax_corrected,
    e50_corrected = e50_corrected,
    e90_corrected = e90_corrected,
    r2_corrected = r2_corrected,
    ici_corrected = ici_corrected
  )
  
  #summary of results (sd pooled according to cohen 1988 https://www.statisticshowto.com/pooled-standard-deviation/)
  auc_df_summary <- auc_df  %>%
  summarise(
    m_auc_apparent = mean(auc_apparent),
    se_auc_apparent = sd(auc_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    m_auc_corrected = mean(auc_corrected, na.rm = TRUE),
    se_auc_corrected = sd(auc_corrected, na.rm = TRUE)/sqrt(n_bootstrap),
    
    m_brier_score_apparent = mean(brier_score_apparent, na.rm = TRUE),
    se_brier_score_apparent = sd(brier_score_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    m_brier_score_corrected = mean(brier_score_corrected, na.rm = TRUE),
    se_brier_score_corrected = sd(brier_score_corrected, na.rm = TRUE)/sqrt(n_bootstrap),
    
    m_e50_apparent = mean(e50_apparent, na.rm = TRUE),
    se_e50_apparent = sd(e50_apparent)/sqrt(n_bootstrap),
    m_e50_corrected = mean(e50_corrected, na.rm = TRUE),
    se_e50_corrected = sd(e50_corrected)/sqrt(n_bootstrap),
    
    m_emax_apparent = mean(emax_apparent, na.rm = TRUE),
    se_emax_apparent = sd(emax_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    m_emax_corrected = mean(emax_corrected, na.rm = TRUE),
    se_emax_corrected = sd(emax_corrected)/sqrt(n_bootstrap),
    
    m_e90_apparent = mean(e90_apparent, na.rm = TRUE),
    se_e90_apparent = sd(e90_apparent)/sqrt(n_bootstrap),
    m_e90_corrected = mean(e90_corrected, na.rm = TRUE),
    se_e90_corrected = sd(e90_corrected)/sqrt(n_bootstrap),
    
    m_ici_apparent = mean(ici_apparent, na.rm = TRUE),
    se_ici_apparent = sd(ici_apparent)/sqrt(n_bootstrap),
    m_ici_corrected = mean(ici_corrected, na.rm = TRUE),
    se_ici_corrected = sd(ici_corrected)/sqrt(n_bootstrap),
    
    m_r2_apparent = mean(r2_apparent, na.rm = TRUE),
    se_r2_apparent = sd(r2_apparent)/sqrt(n_bootstrap),
    m_r2_corrected = mean(r2_corrected, na.rm = TRUE),
    se_r2_corrected = sd(r2_corrected)/sqrt(n_bootstrap),
    
    m_aic_apparent = mean(aic_apparent, na.rm = TRUE),
    se_aic_apparent = sd(aic_apparent)/sqrt(n_bootstrap)
  )
  
  return(auc_df_summary)
}
```

**Boostrap function for internal validation**
```{r, eval=FALSE}
#define bootstrap function
bootstrap_validation_logreg_external <- function(data, n_bootstrap) {
  
  #make storage for apparent values (original model tested on bootstrap dataset)
  auc_values_apparent <- numeric(n_bootstrap)
  brier_score_apparent <- numeric(n_bootstrap) 
  emax_apparent <- numeric(n_bootstrap)
  e50_apparent <- numeric(n_bootstrap)
  e90_apparent <- numeric(n_bootstrap)
  r2_apparent <- numeric(n_bootstrap)
  ici_apparent <- numeric(n_bootstrap)

  for(i in 1:n_bootstrap) {
    #resampling indices
    bootstrap_data <- sample_n(data, nrow(data), replace = TRUE)

    #predict on the bootstrap sample
    bootstrap_data <- bootstrap_data %>%
      mutate(logodds_intercept = ifelse("(Intercept)" %in% coefficients$term, coefficients$estimate[coefficients$term == "(Intercept)"], 0),
             across(all_of(fixed_vars_coded), ~ .x * coefficients_list[[cur_column()]], .names = "logodds_{.col}")
             ) %>%
      mutate(odds_vte = exp(rowSums(select(., starts_with("log")), na.rm = TRUE)),
         prob_vte = odds_vte / (1 + odds_vte))
    
    #calculate apparent discrimination
    
    #store apparent values
    auc_result_apparent <- roc(bootstrap_data$status_dich, bootstrap_data$prob_vte, ci = TRUE, direction = "<")
    apparent_cal <- val.prob(bootstrap_data$prob_vte, bootstrap_data$status_dich, pl = FALSE)
    auc_values_apparent[i] <- auc_result_apparent$auc
    brier_score_apparent[i] <- mean((bootstrap_data$prob_vte - as.numeric(bootstrap_data$status_dich))^2)
    emax_apparent[i] <- apparent_cal[[14]]
    e50_apparent[i] <- unname(quantile(abs(bootstrap_data$prob_vte - approx(lowess(bootstrap_data$prob_vte, bootstrap_data$status_dich, iter=0), xout=bootstrap_data$prob_vte, ties=mean)$y), 0.5))
    e90_apparent[i] <- apparent_cal[[15]] 
    r2_apparent[i] <- apparent_cal[[3]] 
    ici_apparent[i] <- apparent_cal[[16]]

    
  }
  
  #pooling the results directly in the function
  auc_df <- data.frame(
    auc_apparent = auc_values_apparent,
    brier_score_apparent = brier_score_apparent,
    emax_apparent = emax_apparent,
    e50_apparent = e50_apparent,
    e90_apparent = e90_apparent,
    r2_apparent = r2_apparent,
    ici_apparent = ici_apparent
    
  )
  
  #summary of results (sd pooled according to cohen 1988 https://www.statisticshowto.com/pooled-standard-deviation/)
  auc_df_summary <- auc_df %>%
    summarise(
     m_auc_apparent = mean(auc_apparent, na.rm = TRUE),
    se_auc_apparent = sd(auc_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    
    m_brier_score_apparent = mean(brier_score_apparent, na.rm = TRUE),
    se_brier_score_apparent = sd(brier_score_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    
    m_e50_apparent = mean(e50_apparent, na.rm = TRUE),
    se_e50_apparent = sd(e50_apparent)/sqrt(n_bootstrap),

    m_emax_apparent = mean(emax_apparent, na.rm = TRUE),
    se_emax_apparent = sd(emax_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
 
    m_e90_apparent = mean(e90_apparent, na.rm = TRUE),
    se_e90_apparent = sd(e90_apparent)/sqrt(n_bootstrap),

    m_r2_apparent = mean(r2_apparent, na.rm = TRUE),
    se_r2_apparent = sd(r2_apparent)/sqrt(n_bootstrap),
    
    m_ici_apparent = mean(ici_apparent, na.rm = TRUE),
    se_ici_apparent = sd(ici_apparent)/sqrt(n_bootstrap)
    )
  
  return(auc_df_summary)
}
```

**Running the boostrap validation and making summary tables in the development set**
```{r, eval=FALSE}
#set model variables to be validated 

n_bootstrap <- 200

#combine all results into a single data frame
final_results_internal_validation <- bootstrap_validation_logreg(mimic, n_bootstrap)

#extract metrics
df_metrics <- pivot_longer(final_results_internal_validation, 
                        cols = -starts_with("se_"), 
                        names_to = "metric", 
                        values_to = "value")%>%
      mutate( metric = gsub("m_", "", metric))

#extract the se columns into a separate data frame
df_se <- pivot_longer(final_results_internal_validation, 
                      cols = starts_with("se_"), 
                      names_to = "metric_se", 
                      values_to = "se")

#remove 'se_' prefix to match metric names so we can left join them
df_se$metric_se <- sub("se_", "", df_se$metric_se)

#merge the value and se columns by matching metric names
all_metrics_df <- left_join(df_metrics, df_se, by = c("metric" = "metric_se"))%>%
  select(metric, value, se)


all_metrics_df <- all_metrics_df %>%
  mutate(
    value = signif(value, digits = 3),
    lower_ci = signif(value - se*1.96, digits = 3),
    upper_ci= signif(value + se*1.96, digits = 3),
     `Value (95% CI)` = paste(value, paste("(", lower_ci, "-",upper_ci, ")", sep = "")))%>%
  select(Metric = metric, `Value (95% CI)` )


apparent_metrics_df <- all_metrics_df %>%
  filter(grepl("apparent", Metric)) %>%
  mutate(`Apparent value` = gsub(" .*", "", `Value (95% CI)`),
          Metric = gsub("_.*", "", Metric)) %>%
  select(Metric, `Apparent value`)

corrected_metrics_df <- all_metrics_df %>%
  filter(grepl("corrected", Metric)) %>%
  mutate(Metric = gsub("_.*", "", Metric)) %>%
  select(Metric, `Corrected value (95% CI)` = `Value (95% CI)`)

printable_model_metrics  <- apparent_metrics_df %>%
  filter(Metric == "aic" & Metric == "r2") %>%
  mutate(Metric = case_when(
    Metric == "aic" ~ "Akaike information criterion",
    Metric == "r2" ~ "Coefficient of determination",
  ))%>%
  kbl("html", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Times")

printable_internal_validation <- left_join(apparent_metrics_df, corrected_metrics_df, by = "Metric") %>%
  filter(Metric != "aic" & Metric != "r2" & Metric != "brier") %>%
  mutate(Metric = as.factor(case_when(
    Metric == "auc" ~ "C-statistic",
    Metric == "ici" ~ "Integrated Calibration Index",
    Metric == "emax" ~ "Emax",
    Metric == "e50" ~ "E50",
    Metric == "e90" ~ "E90"
  )))%>%
    mutate(Metric = factor(Metric, levels = c("C-statistic", "Integrated Calibration Index",  "E50", "E90", "Emax"))) %>%
    arrange(Metric) %>%
  kbl("html", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Times")


```

**Calculating the average predicted risk per patient in the development cohort**
```{r, eval=FALSE}
mimic_prob <- mimic %>%
  mutate(
    logodds_intercept = ifelse("(Intercept)" %in% coefficients$term, coefficients$estimate[coefficients$term == "(Intercept)"], 0),
    across(all_of(fixed_vars_coded), ~ .x * coefficients_list[[cur_column()]], .names = "logodds_{.col}")
  ) %>%
  mutate(odds_vte = exp(rowSums(select(., starts_with("log")), na.rm = TRUE)),
         prob_vte = odds_vte / (1 + odds_vte))

```

**Making calibration + density plot for internal validation**
```{r, eval=FALSE}
percentile_95 <- quantile(mimic_prob$prob_vte, probs = 0.95)

internal_validation_1 <- ggplot(mimic_prob, aes(x = prob_vte, y = status_dich)) +
 geom_smooth(color = "darkblue", method = "loess", se = FALSE, size = 0.5, span = 0.75) + #LOESS smooth line
  stat_smooth(color = "darkred", method="glm", family="binomial", se=F, size = 0.5) + 
  geom_vline(xintercept = percentile_95, linetype = "dashed", color = "gray", size = 0.5) + #95th percentile line
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.05)) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.05)) +
  geom_abline(size = 4, alpha = 0.5, color = "gray") + #adds a line with a slope of 1 and intercept of 0 by default
  xlab("") +
  ylab("Observed Probability") +
  theme_minimal() +
  ggtitle(expression(bold("Figure x.") ~ "Calibration curve of internal validation")) +
  coord_cartesian(xlim = c(0, 0.45), ylim = c(0, 0.45)) +
  theme(plot.title = element_text(hjust = 0.5, family = "Times New Roman", face = "bold"),
        text = element_text(family = "Times New Roman"),
        panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        plot.margin = unit(c(1,1,0,1), "lines"))

internal_validation_2 <- ggplot(mimic_prob, aes(x = prob_vte)) +
  geom_histogram(color = "black", fill = NA, binwidth = 0.001) + 
  scale_x_continuous(limits = c(0, 0.45), breaks = seq(0, 0.45, by = 0.05)) +
  xlab("Predicted Probability") +
  ylab("") +
  theme_minimal() +
  theme(text = element_text(family = "Times New Roman"),
        panel.background = element_rect(fill = "white", colour = NA), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(colour = "white"),
        panel.border = element_blank(),  #remove border around the panel
        plot.margin = unit(c(1, -0.6, 1, -0.75), "lines")) +  #reduce padding around the plot
  geom_segment(aes(x = 0, y = 0, xend = 0.45, yend = 0), color = "black", size = 0.05) #add manual border for x-axis from x=0 to x=0.35


legend_plot <- ggplot(data.frame(x = c(0, 1), y = c(0, 1)), aes(x, y)) +
  geom_line(aes(color = "Logistic calibration"), size = 0.5) +
  geom_line(aes(color = "Locally estimated scatterplot smoothing"), size = 0.5) +
    geom_line(aes(color = "95% Percentile of Predicted Risks"), size = 0.5, linetype = "dashed") +
  geom_line(size = 10, show.legend = FALSE, color = "white", fill = "white") + #do not show in legend
  scale_color_manual("", 
                     values = c("Logistic calibration" = "darkred", 
                                "Locally estimated scatterplot smoothing" = "darkblue",
                                "95% Percentile of Predicted Risks" = "gray"
                                )) +
  theme(legend.position = "top", 
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.title.y = element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.x= element_blank(),
        axis.text.y = element_blank(),
        panel.border = element_blank(),
        legend.text = element_text(size = 10, family = "Times New Roman"),
        legend.background = element_rect(fill = "white"),
        legend.key = element_blank())



#combining the adjusted plots
internal_validation_calibration <- arrangeGrob(internal_validation_1, internal_validation_2, legend_plot, 
                             heights = unit(c(3, 1, 0.6), "null"), ncol = 1)
```

**Validating and constructing summary tables for external validation set**
```{r, eval=FALSE}

n_bootstrap <- 200

final_results_external_validation <- bootstrap_validation_logreg_external(sics_bb, n_bootstrap)

#extract metrics
df_metrics <- pivot_longer(final_results_external_validation, 
                        cols = -starts_with("se_"), 
                        names_to = "metric", 
                        values_to = "value")%>%
      mutate( metric = gsub("m_", "", metric))

#extract the se columns into a separate data frame
df_se <- pivot_longer(final_results_external_validation, 
                      cols = starts_with("se_"), 
                      names_to = "metric_se", 
                      values_to = "se")

#remove 'se_' prefix to match metric names so we can left join them
df_se$metric_se <- sub("se_", "", df_se$metric_se) 

df_se <- df_se %>%
  select(metric = metric_se, se)
#merge the value and se columns by matching metric names
all_metrics_df <- left_join(df_metrics, df_se, by = "metric") %>%
  select(metric, value, se)


printable_external_validation <- all_metrics_df %>%
  filter(metric != "r2_apparent" & metric != "brier_score_apparent") %>%
  mutate(
    value = signif(value, digits = 3),
    lower_ci = signif(value - se*1.96, digits = 3),
    upper_ci= signif(value + se*1.96, digits = 3),
     `Value (95% CI)` = paste(value, paste("(", lower_ci, "-",upper_ci, ")", sep = "")))%>%
  select(Metric = metric, `Apparent value (95% CI)` = `Value (95% CI)`)%>%
   mutate(Metric = case_when(
    Metric == "auc_apparent" ~ "C-statistic",
    Metric == "emax_apparent" ~ "Emax",
    Metric == "e50_apparent" ~ "E50",
    Metric == "e90_apparent" ~ "E90",
    Metric == "ici_apparent" ~ "Integrated Calibration Index"
  ))%>%
    mutate(Metric = factor(Metric, levels = c("C-statistic", "Integrated Calibration Index",  "E50", "E90", "Emax"))) %>%
      arrange(Metric) %>%
  kbl("html", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Times")

```

**Calculating the average predicted risk per patient in the external validation cohort**
```{r, eval=FALSE}

sics_bb_prob <- sics_bb %>%
  mutate(logodds_intercept = ifelse("(Intercept)" %in% coefficients$term, coefficients$estimate[coefficients$term == "(Intercept)"], 0),
    across(all_of(fixed_vars_coded), ~ .x * coefficients_list[[cur_column()]], .names = "logodds_{.col}")
  ) %>%
  mutate(odds_vte = exp(rowSums(select(., starts_with("log")), na.rm = TRUE)),
         prob_vte = odds_vte / (1 + odds_vte)) 

```

**Making calibration + density plot for external validation**
```{r, eval=FALSE}
percentile_95 <- quantile(sics_bb_prob$prob_vte, probs = 0.95)

external_validation_1 <- ggplot(sics_bb_prob, aes(x = prob_vte, y = status_dich)) +
  geom_smooth(color = "darkblue", method = "loess", se = FALSE, size = 0.5, span = 0.75) + #LOESS smooth line
  stat_smooth(color = "darkred", method="glm", family="binomial", se=F, size = 0.5) +
  geom_vline(xintercept = percentile_95, linetype = "dashed", color = "gray", size = 0.5) + #95th percentile line
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.05)) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.05)) +
  geom_abline(size = 4, alpha = 0.5, color = "gray") + #adds a line with a slope of 1 and intercept of 0 by default
  xlab("") +
  ylab("Observed Probability") +
  theme_minimal() +
  ggtitle(expression(bold("Figure x.") ~ "Calibration curve of external validation")) +
  coord_cartesian(xlim = c(0, 0.25), ylim = c(0, 0.25)) +
  theme(plot.title = element_text(hjust = 0.5, family = "Times New Roman", face = "bold"),
        text = element_text(family = "Times New Roman"),
        panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        plot.margin = unit(c(1,1,0,1), "lines"))

external_validation_2 <- ggplot(sics_bb_prob, aes(x = prob_vte)) +
  geom_histogram(color = "black", fill = NA, binwidth = 0.001) + 
  scale_x_continuous(limits = c(0, 0.25), breaks = seq(0, 0.25, by = 0.05)) +
  xlab("Predicted Probability") +
  ylab("") +
  theme_minimal() +
  theme(text = element_text(family = "Times New Roman"),
        panel.background = element_rect(fill = "white", colour = NA), #remove border color
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(colour = "white"),
        panel.border = element_blank(), #add line for x-axis border
        plot.margin = unit(c(1, -0.5, 1, -0.5), "lines")) +  #reduce padding around the plot
  geom_segment(aes(x = 0, y = 0, xend = 0.25, yend = 0), color = "black", size = 0.05) #add manual border for x-axis from x=0 to x=0.25

legend_plot <- ggplot(data.frame(x = c(0, 1), y = c(0, 1)), aes(x, y)) +
  geom_line(aes(color = "Logistic calibration"), size = 0.5) +
  geom_line(aes(color = "Locally estimated scatterplot smoothing"), size = 0.5) +
    geom_line(aes(color = "95% Percentile of Predicted Risks"), size = 0.5, linetype = "dashed") +
  geom_line(size = 10, show.legend = FALSE, color = "white", fill = "white") + #do not show in legend
  scale_color_manual("", 
                     values = c("Logistic calibration" = "darkred", 
                                "Locally estimated scatterplot smoothing" = "darkblue",
                                "95% Percentile of Predicted Risks" = "gray"
                                )) +
  theme(legend.position = "top", 
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.title.y = element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.x= element_blank(),
        axis.text.y = element_blank(),
        panel.border = element_blank(),
        legend.text = element_text(size = 10, family = "Times New Roman"),
        legend.background = element_rect(fill = "white"),
        legend.key = element_blank())


#combining the adjusted plots
external_validation_calibration <- arrangeGrob(external_validation_1, external_validation_2, legend_plot, 
                             heights = unit(c(3, 1, 0.6), "null"), widths = 1 ,ncol = 1)
```

**Save environment**
```{r, eval=FALSE}
save.image(file ='multiple_logistic_reg_mi_environment_complete_case.RData')
```

**Load environment**
```{r}
load('multiple_logistic_reg_mi_environment_complete_case.RData')
```

**Presenting ORs of final model**
```{r message=FALSE, warning=FALSE}
or_print
```

**Visualizing ORs of final model**
```{r fig.height=8, fig.width=8}
stacked_plots
```

**Summary table for internal validation**
```{r message=FALSE, warning=FALSE}
printable_internal_validation
```

**Calibration in development set**
```{r fig.height=8, fig.width=8}
grid.newpage()
grid.draw(internal_validation_calibration)
```


**Summary table for external validation**
```{r message=FALSE, warning=FALSE}
printable_external_validation
```

**Calibration in external validation set**
```{r fig.height=8, fig.width=8}
grid.newpage()
grid.draw(external_validation_calibration)
```



