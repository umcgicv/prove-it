---
title: "PROVE-IT LASSO, complete case analysis"
author: "SCS Rivrud, RJ Eck, ERH Heijkoop"
output:
  html_document:
    df_print: paged
    code_folding: hide
---

**Load packages**
```{r include=FALSE}
library(tidyverse)
library(pacman)
library(adjustedCurves)
library(dcurves)
library(ResourceSelection)
library(here)
library(adjustedCurves)
library(gmish)
library(mice)
library(scales)
library(miceadds)
library("plotrix")
library(DescTools)
library(foreach)
library(doParallel)
library(pROC)
library(future)
library(gridExtra)
#install.packages("remotes")
#remotes::install_github("3inar/einr")
library(contsurvplot)
library(precrec)
library(PRROC)
library(broom)
library(plotROC)
library(Greg)
library(future.apply)
library(glmnet)
library(sAIC)
library(timeROC)
library(survivalROC)
pacman::p_load(
  survival,
  rms,
  cmprsk,
  riskRegression,
  mstate,
  pseudo,
  pec,
  plotrix,
  knitr,
  splines,
  kableExtra,
  gtsummary,
  boot,
  rsample,
  gridExtra,
  webshot,
  tidycmprsk,  
  Hmisc,
  data.table,
  lubridate,
  here,
  DBI,
  RSQLite,
  pROC,
  reshape2,
  dbplyr,
  stringr,
  readxl,
  writexl,
  stringi,
  devtools,
  ggsurvfit,
  tidyr,
  dplyr,
  ggplot2,
  mgcv,
  pammtools
)
library(caret)
library(glmnet)
library(einr)
set.seed(42) #set seed
```

**Function for bootstrapping with optimism correct**
```{r, eval=FALSE}
#define bootstrap function
bootstrap_validation_logreg <- function(data, response, app_cv_fit, app_best_lambda, n_bootstrap) {
  
  #make storage for apparent values (original model tested on bootstrap dataset)
  auc_values_apparent <- numeric(n_bootstrap)
  brier_score_apparent <- numeric(n_bootstrap) 
  emax_apparent <- numeric(n_bootstrap)
  e50_apparent <- numeric(n_bootstrap)
  e90_apparent <- numeric(n_bootstrap)
  r2_apparent <- numeric(n_bootstrap)
  ici_apparent <- numeric(n_bootstrap)

  #make storage for original values (bootstrap model tested on original dataset)
  auc_values_corrected <- numeric(n_bootstrap)
  brier_score_corrected <- numeric(n_bootstrap) 
  emax_corrected <- numeric(n_bootstrap)
  e50_corrected <- numeric(n_bootstrap)
  e90_corrected <- numeric(n_bootstrap)
  r2_corrected <- numeric(n_bootstrap)
  ici_corrected <- numeric(n_bootstrap)
  
  for(i in 1:n_bootstrap) {
    
    #resampling indices
    bootstrap_indices <- sample(1:nrow(data), replace = TRUE)
    bootstrap_data <- data[bootstrap_indices, ]
    bootstrap_response <- response[bootstrap_indices]

    #fit on apparant
    boot_cv_fit <- cv.glmnet(bootstrap_data, y=bootstrap_response, alpha=1, nfolds=20, family="binomial")
    boot_best_lambda <- boot_cv_fit$lambda.min

    #calculate apparent discrimination
    data_prob_vte <- predict(app_cv_fit, newx = data, s = app_best_lambda, type = "response")
    
    #store apparent values
    auc_result_apparent <- roc(response, data_prob_vte[,1], ci = TRUE, direction = "<")
    apparent_cal <- rms::val.prob(data_prob_vte[,1], response, pl=FALSE)
    e50_ap <- unname(quantile(abs(data_prob_vte[,1] - approx(lowess(data_prob_vte[,1], response, iter=0), xout=data_prob_vte[,1], ties=mean)$y), 0.5))

        
    #store bootstrapped values
    boot_prob_vte <- predict(boot_cv_fit, newx = bootstrap_data, s = boot_best_lambda, type = "response")
    auc_boot <- roc(bootstrap_response, boot_prob_vte[,1], ci = TRUE, direction = "<")
    auc_values_boot <- auc_boot$auc
    boot_cal <- val.prob(boot_prob_vte[,1], bootstrap_response, pl=FALSE)
    e50_boot <- unname(quantile(abs(boot_prob_vte[,1] - approx(lowess(boot_prob_vte[,1], bootstrap_response, iter=0), xout=boot_prob_vte[,1], ties=mean)$y), 0.5))


    #store original score
    orig_prob_vte <- predict(boot_cv_fit, newx = data, s = boot_best_lambda, type = "response")
    auc_original <- roc(response, orig_prob_vte[,1], ci = TRUE, direction = "<")
    auc_values_original <- auc_original$auc
    orig_cal <- val.prob(orig_prob_vte[,1], response, pl=FALSE)
    e50_orig <- unname(quantile(abs(orig_prob_vte[,1] - approx(lowess(orig_prob_vte[,1], response, iter=0), xout=orig_prob_vte[,1], ties=mean)$y), 0.5))

    #calculate the corrected score
    auc_values_corrected[i] <- (auc_result_apparent$auc) - abs(auc_values_boot - auc_values_original)
    brier_score_corrected[i] <- mean((data_prob_vte[,1] + as.numeric(response))^2) - abs(mean((boot_prob_vte[,1] - bootstrap_response)^2) - mean((orig_prob_vte[,1] - response)^2))
    emax_corrected[i] <- apparent_cal[[14]] + abs(boot_cal[[14]]  - orig_cal[[14]])
    ici_corrected[i] <- apparent_cal[[16]] + abs(boot_cal[[16]]  - orig_cal[[16]])
    e90_corrected[i] <- apparent_cal[[15]] + abs(boot_cal[[15]]  - orig_cal[[15]])
    r2_corrected[i] <- apparent_cal[[3]] - abs(boot_cal[[3]]  - orig_cal[[3]])
    e50_corrected[i] <- e50_ap + abs(e50_boot - e50_orig)


    #calculate apparent score
    auc_values_apparent[i] <- auc_result_apparent$auc
    brier_score_apparent[i] <- mean((data_prob_vte[,1] - response)^2)
    emax_apparent[i] <- apparent_cal[[14]]
    ici_apparent[i] <- apparent_cal[[16]]
    e90_apparent[i] <- apparent_cal[[15]] 
    r2_apparent[i] <- apparent_cal[[3]] 
    e50_apparent[i] <- e50_ap

  }
  
  #pooling the results directly in the function
  auc_df <- data.frame(
    
    auc_apparent = auc_values_apparent,
    brier_score_apparent = brier_score_apparent,
    emax_apparent = emax_apparent,
    e50_apparent = e50_apparent,
    e90_apparent = e90_apparent,
    r2_apparent = r2_apparent,
    ici_apparent = ici_apparent,
    
    auc_corrected = auc_values_corrected,
    brier_score_corrected = brier_score_corrected,
    emax_corrected = emax_corrected,
    e50_corrected = e50_corrected,
    e90_corrected = e90_corrected,
    r2_corrected = r2_corrected,
    ici_corrected = ici_corrected
  )
  
 auc_df_summary <- auc_df  %>%
  summarise(
    m_auc_apparent = mean(auc_apparent),
    se_auc_apparent = sd(auc_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    m_auc_corrected = mean(auc_corrected, na.rm = TRUE),
    se_auc_corrected = sd(auc_corrected, na.rm = TRUE)/sqrt(n_bootstrap),
    
    m_brier_score_apparent = mean(brier_score_apparent, na.rm = TRUE),
    se_brier_score_apparent = sd(brier_score_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    m_brier_score_corrected = mean(brier_score_corrected, na.rm = TRUE),
    se_brier_score_corrected = sd(brier_score_corrected, na.rm = TRUE)/sqrt(n_bootstrap),
    
    m_emax_apparent = mean(emax_apparent, na.rm = TRUE),
    se_emax_apparent = sd(emax_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    m_emax_corrected = mean(emax_corrected, na.rm = TRUE),
    se_emax_corrected = sd(emax_corrected)/sqrt(n_bootstrap),
    
    m_e50_apparent = mean(e50_apparent, na.rm = TRUE),
    se_e50_apparent = sd(e50_apparent)/sqrt(n_bootstrap),
    m_e50_corrected = mean(e50_corrected, na.rm = TRUE),
    se_e50_corrected = sd(e50_corrected)/sqrt(n_bootstrap),
    
    m_e90_apparent = mean(e90_apparent, na.rm = TRUE),
    se_e90_apparent = sd(e90_apparent)/sqrt(n_bootstrap),
    m_e90_corrected = mean(e90_corrected, na.rm = TRUE),
    se_e90_corrected = sd(e90_corrected)/sqrt(n_bootstrap),
    
    m_ici_apparent = mean(ici_apparent, na.rm = TRUE),
    se_ici_apparent = sd(ici_apparent)/sqrt(n_bootstrap),
    m_ici_corrected = mean(ici_corrected, na.rm = TRUE),
    se_ici_corrected = sd(ici_corrected)/sqrt(n_bootstrap),
    
    m_r2_apparent = mean(r2_apparent, na.rm = TRUE),
    se_r2_apparent = sd(r2_apparent)/sqrt(n_bootstrap),
    m_r2_corrected = mean(r2_corrected, na.rm = TRUE),
    se_r2_corrected = sd(r2_corrected)/sqrt(n_bootstrap)
    
  )
  return(auc_df_summary)
}
```

**Load and prepare dataset**
```{r eval=FALSE}
mimic <- readRDS("analysis subsets/complete_mimic.RDS")

fixed_vars <- c("cvl","previousvte", "malignancy", "median_temp", "rr_median", "lactate", "wbc", "surgical_30_days", "vasoactives","mech_vent", "anticoag_proph_24", "weight", "median_heart_rate", "median_bp_map")


mimic <- mimic %>%
  mutate(cvl = as.factor(cvl),
         sex = as.factor(
           case_when(
             sex == "M" ~ 1,
             TRUE ~ 0
           )),
         rr_median = rr_median/5,
         lactate = lactate,
         wbc = wbc/5,
         weight = weight/10,
         median_bp_map = median_bp_map/10,
         median_heart_rate = median_heart_rate/10
         ) %>%
    select(all_of(c("subject_id","status_dich", fixed_vars))) %>%
    mutate(across(c("malignancy", "cvl", "previousvte", "surgical_30_days", 
                  "mech_vent", "vasoactives", "anticoag_proph_24"),
                ~as.numeric(as.character(.)),
                .names = "{.col}1")
           ) %>%
  na.omit()

n_bootstrap <- 200

  #create model matrix for binary outcome
xfactors <- model.matrix(mimic$status_dich ~ 
                           mimic$malignancy + 
                           mimic$previousvte + 
                           mimic$cvl + 
                           mimic$vasoactives + 
                           mimic$mech_vent + 
                           mimic$surgical_30_days +
                           mimic$anticoag_proph_24
)[, -1]

#subset remaining (cont.) variables
data_cont <- mimic %>%
  select(weight, wbc, median_heart_rate, rr_median, median_bp_map,  median_temp, lactate)

#create matrix of all variables
data_matrix <- as.matrix(cbind(xfactors, data_cont))

y_mimic <- mimic$status_dich
  

#fit on apparent set
set.seed(42)
app_cv_fit <- cv.glmnet(data_matrix, y=y_mimic, alpha=1, nfolds=20, family="binomial")
app_best_lambda <- app_cv_fit$lambda.min

#apply the bootstrap validation function
final_results_internal_validation <- bootstrap_validation_logreg(data_matrix, y_mimic,app_cv_fit,  app_best_lambda, n_bootstrap)

#extract metrics
df_metrics <- pivot_longer(final_results_internal_validation, 
                        cols = -starts_with("se_"), 
                        names_to = "metric", 
                        values_to = "value")

#extract the se columns into a separate data frame
df_se <- pivot_longer(final_results_internal_validation, 
                      cols = starts_with("se_"), 
                      names_to = "metric_se", 
                      values_to = "se")

#remove 'se_' prefix to match metric names so we can left join them
df_se$metric_se <- sub("se_", "", df_se$metric_se)
df_metrics$metric <- sub("m_", "", df_metrics$metric)

#merge the value and se columns by matching metric names
all_metrics_df <- left_join(df_metrics, df_se, by = c("metric" = "metric_se"))

# Rename the columns appropriately
all_metrics_df <- all_metrics_df %>% select(metric, value, se)


all_metrics_df <- all_metrics_df %>%
  mutate(
    value = signif(value, digits = 3),
    lower_ci = signif(value - se*1.96, digits = 3),
    upper_ci= signif(value + se*1.96, digits = 3),
     `Value (95% CI)` = paste(value, paste("(", lower_ci, "-",upper_ci, ")", sep = "")))%>%
  select(Metric = metric, `Value (95% CI)` )


apparent_metrics_df <- all_metrics_df %>%
  filter(grepl("apparent", Metric)) %>%
  mutate(Metric = gsub("_.*", "", Metric)) %>%
  select(Metric, `Apparent value (95% CI)` = `Value (95% CI)`)

corrected_metrics_df <- all_metrics_df %>%
  filter(grepl("corrected", Metric)) %>%
  mutate(Metric = gsub("_.*", "", Metric)) %>%
  select(Metric, `Corrected value (95% CI)` = `Value (95% CI)`)

printable_model_metrics  <- apparent_metrics_df %>%
  filter(Metric == "aic" & Metric == "r2") %>%
  mutate(Metric = case_when(
    Metric == "aic" ~ "Akaike information criterion",
    Metric == "r2" ~ "Coefficient of determination",
  ))%>%
  kbl("html", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Times")

printable_internal_validation <- left_join(apparent_metrics_df, corrected_metrics_df, by = "Metric") %>%
  filter(Metric != "aic" & Metric != "r2" & Metric != "brier") %>%
  mutate(Metric = case_when(
    Metric == "auc" ~ "C-statistic",
    Metric == "emax" ~ "Emax",
    Metric == "e50" ~ "E50",
    Metric == "e90" ~ "E90",
    Metric == "ici" ~ "Integrated Calibration Index"
  ))%>%
  mutate(Metric = factor(Metric, levels = c("C-statistic", "Integrated Calibration Index",  "E50", "E90", "Emax"))) %>%
  arrange(Metric) %>%
  kbl("html", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Times")

```

**Extract coefficients**
```{r, eval=FALSE}
  #fit the model with the best lambda
  fit_best <- glmnet(data_matrix, y_mimic, alpha=1, family="binomial", lambda=app_best_lambda, intercept = TRUE)
  
  #extract and clean coefficients
  coefficients <- coef(fit_best, s=app_best_lambda) %>%
    as.matrix() %>%
    as.data.frame() %>%
    rownames_to_column(var = "term") %>%
    rename(estimate = s1) %>%
    mutate(OR = as.numeric(exp(estimate))) %>%
    select(Term = term, OR) %>%
    mutate(Term = str_replace(Term, "mimic\\$", ""),
           Term = case_when(
    Term == "rr_median" ~ "Respiratory rate per 5 unit increase",
    Term == "median_bp_map" ~ "Mean arterial blood pressure per 10 mmHg increase",
    Term == "lactate" ~ "Lactate per 1 mmol/L increase",
    Term == "weight" ~ "Weight per 10 kg increase",
    Term == "wbc" ~ "White blood cell count per 5 K/uL increase",
    Term == "median_heart_rate" ~ "Heart rate per 10 bpm increase",
    Term == "vasoactives1" ~ "Vasopressors within 24 hours of ICU admission",
    Term == "mech_vent1" ~ "Mechanical ventilation within 24 hours of ICU admission",
    Term == "malignancy1" ~ "Active malignancy",
    Term == "surgical_30_days1" ~ "Surgical ICU admission",
    Term == "previousvte1" ~ "Personal history of VTE",
    Term == "cvl1" ~ "Central venous line within 24 hours of ICU admission",
    Term == "(Intercept)" ~ "Intercept",
    Term == "anticoag_proph_241" ~ "Thromboprophylaxis within 24 hours of ICU admission",
    Term == "median_temp" ~ "Body temperature per 1°C increase",
    TRUE ~ Term
  )) 
  
printable_or <- coefficients  %>%
  kbl("html", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Times")
  
 #extract and clean coefficients
  coefficients <- coef(fit_best, s=app_best_lambda) %>%
    as.matrix() %>%
    as.data.frame() %>%
    rownames_to_column(var = "term") %>%
    rename(estimate = s1) %>%
    select(Term = term, Coefficients = estimate) %>%
    mutate(Term = str_replace(Term, "mimic\\$", ""),
           Term = case_when(
    Term == "rr_median" ~ "Respiratory rate per 5 unit increase",
    Term == "median_bp_map" ~ "Mean arterial blood pressure per 10 mmHg increase",
    Term == "lactate" ~ "Lactate per 1 mmol/L increase",
    Term == "weight" ~ "Weight per 10 kg increase",
    Term == "wbc" ~ "White blood cell count per 5 K/uL increase",
    Term == "median_heart_rate" ~ "Heart rate per 10 bpm increase",
    Term == "vasoactives1" ~ "Vasopressors within 24 hours of ICU admission",
    Term == "mech_vent1" ~ "Mechanical ventilation within 24 hours of ICU admission",
    Term == "malignancy1" ~ "Active malignancy",
    Term == "surgical_30_days1" ~ "Surgical ICU admission",
    Term == "previousvte1" ~ "Personal history of VTE",
    Term == "cvl1" ~ "Central venous line within 24 hours of ICU admission",
    Term == "(Intercept)" ~ "Intercept",
    Term == "anticoag_proph_241" ~ "Thromboprophylaxis within 24 hours of ICU admission",
    Term == "median_temp" ~ "Body temperature per 1°C increase",
    TRUE ~ Term
  )) 

  printable_coef <- coefficients  %>%
  kbl("html", escape = FALSE) %>%
  kable_classic(full_width = F, html_font = "Times")
```

**Calculating the average predicted risk per patient in the external validation cohort**
```{r, eval=FALSE}
coefficients <- coef(fit_best, s=app_best_lambda) %>%
    as.matrix() %>%
    as.data.frame() %>%
    rownames_to_column(var = "term") %>%
    rename(estimate = s1) %>%
  mutate(estimate = as.numeric(estimate),
         term = str_replace(term, "mimic\\$", ""))

mimic_prob <- mimic %>% #some were 0
mutate(odds_vte = exp(coefficients$estimate[coefficients$term == "(Intercept)"] + 
                        coefficients$estimate[coefficients$term == "cvl1"] * cvl1 + 
                        coefficients$estimate[coefficients$term == "previousvte1"] * previousvte1 + 
                         coefficients$estimate[coefficients$term == "mech_vent1"] * mech_vent1 +
                         coefficients$estimate[coefficients$term == "median_temp"] * median_temp +
                         coefficients$estimate[coefficients$term == "median_heart_rate"] * median_heart_rate +
                         coefficients$estimate[coefficients$term == "median_bp_map"] * median_bp_map +
                         coefficients$estimate[coefficients$term == "weight"] * weight +
                         coefficients$estimate[coefficients$term == "vasoactives1"] * vasoactives1 +
                         coefficients$estimate[coefficients$term == "malignancy1"] * malignancy1 +
                         coefficients$estimate[coefficients$term == "wbc"] * wbc +
                         coefficients$estimate[coefficients$term == "rr_median"] * rr_median +
                         coefficients$estimate[coefficients$term == "anticoag_proph_241"] * anticoag_proph_241 +
                         coefficients$estimate[coefficients$term == "lactate"] * lactate +
                         coefficients$estimate[coefficients$term == "surgical_30_days1"] * surgical_30_days1

),
         prob_vte = odds_vte / (1 + odds_vte))
```

**Making calibration + density plot for internal validation**
```{r eval=FALSE}
#the calibration plot according to https://darrendahly.github.io/post/homr/        
percentile_95 <- quantile(mimic_prob$prob_vte, probs = 0.95)

internal_validation_1 <- ggplot(mimic_prob, aes(x = prob_vte, y = status_dich)) +
 geom_smooth(color = "darkblue", method = "loess", se = FALSE, size = 0.5, span = 0.75) + #LOESS smooth line
  stat_smooth(color = "darkred", method="glm", family="binomial", se=F, size = 0.5) + 
  geom_vline(xintercept = percentile_95, linetype = "dashed", color = "gray", size = 0.5) + #95th percentile line
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.05)) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.05)) +
  geom_abline(size = 4, alpha = 0.5, color = "gray") + #adds a line with a slope of 1 and intercept of 0 by default
  xlab("") +
  ylab("Observed Probability") +
  theme_minimal() +
  ggtitle(expression(bold("Figure x.") ~ "Calibration curve of internal validation")) +
  coord_cartesian(xlim = c(0, 0.45), ylim = c(0, 0.45)) +
  theme(plot.title = element_text(hjust = 0.5, family = "Times New Roman", face = "bold"),
        text = element_text(family = "Times New Roman"),
        panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        plot.margin = unit(c(1,1,0,1), "lines"))

internal_validation_2 <- ggplot(mimic_prob, aes(x = prob_vte)) +
  geom_histogram(color = "black", fill = NA, binwidth = 0.001) + 
  scale_x_continuous(limits = c(0, 0.45), breaks = seq(0, 0.45, by = 0.05)) +
  xlab("Predicted Probability") +
  ylab("") +
  theme_minimal() +
  theme(text = element_text(family = "Times New Roman"),
        panel.background = element_rect(fill = "white", colour = NA), 
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(colour = "white"),
        panel.border = element_blank(),  #remove border around the panel
        plot.margin = unit(c(1, -0.6, 1, -0.75), "lines")) +  #reduce padding around the plot
  geom_segment(aes(x = 0, y = 0, xend = 0.45, yend = 0), color = "black", size = 0.05) #add manual border for x-axis from x=0 to x=0.35


legend_plot <- ggplot(data.frame(x = c(0, 1), y = c(0, 1)), aes(x, y)) +
  geom_line(aes(color = "Logistic calibration"), size = 0.5) +
  geom_line(aes(color = "Locally estimated scatterplot smoothing"), size = 0.5) +
    geom_line(aes(color = "95% Percentile of Predicted Risks"), size = 0.5, linetype = "dashed") +
  geom_line(size = 10, show.legend = FALSE, color = "white", fill = "white") + #do not show in legend
  scale_color_manual("", 
                     values = c("Logistic calibration" = "darkred", 
                                "Locally estimated scatterplot smoothing" = "darkblue",
                                "95% Percentile of Predicted Risks" = "gray"
                                )) +
  theme(legend.position = "top", 
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.title.y = element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.x= element_blank(),
        axis.text.y = element_blank(),
        panel.border = element_blank(),
        legend.text = element_text(size = 10, family = "Times New Roman"),
        legend.background = element_rect(fill = "white"),
        legend.key = element_blank())



#combining the adjusted plots
internal_validation_calibration <- arrangeGrob(internal_validation_1, internal_validation_2, legend_plot, 
                             heights = unit(c(3, 1, 0.6), "null"), ncol = 1)
```

**Save R environment**
```{r, eval=FALSE}
save.image(file ='lasso_complete_case_environment.RData')
```

**Load R environment**
```{r}
load('lasso_complete_case_environment.RData')
```

**Coefficients and OR**
```{r}
printable_coef
printable_or
```

**Internal validation stats**
```{r}
printable_internal_validation
```

**print internal validation calibration plot**
```{r fig.height=8, fig.width=8}
grid.newpage()
grid.draw(internal_validation_calibration)
```


