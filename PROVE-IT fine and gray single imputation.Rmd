---
title: "PROVE-IT fine and gray, single imputation"
author: "SCS Rivrud, RJ Eck, ERH Heijkoop"
output:
  html_document:
    code_folding: hide
---
**Load packages**
```{r message=FALSE, warning=FALSE}
pacman::p_load(
  quarto,
  qreport,
  tidyverse,
  survival,
  rms,
  cmprsk,
  riskRegression,
  mstate,
  pseudo,
  pec,
  plotrix,
  knitr,
  splines,
  kableExtra,
  grid,
  gtsummary,
  pROC,
  boot,
  rsample,
  gridExtra,
  webshot,
  sparkline,
  mice,
  httpgd,
  lspline
)
set.seed(42)
```

**Boostrap function for internal validation**
```{r eval=FALSE}
#define bootstrap function
bootstrap_validation_cr <- function(data, n_bootstrap, model_full, primary_event, horizon) {
  
  #make storage for apparent values (original model tested on bootstrap dataset)
  auc_values_apparent <- numeric(n_bootstrap)
  emax_apparent <- numeric(n_bootstrap)
  e50_apparent <- numeric(n_bootstrap)
  e90_apparent <- numeric(n_bootstrap)
  ici_apparent <- numeric(n_bootstrap)

  #make storage for original values (bootstrap model tested on original dataset)
  auc_values_corrected <- numeric(n_bootstrap)
  emax_corrected <- numeric(n_bootstrap)
  e50_corrected <- numeric(n_bootstrap)
  e90_corrected <- numeric(n_bootstrap)
  ici_corrected <- numeric(n_bootstrap)
  
  
  for(i in 1:n_bootstrap) {
    #resampling indices
    bootstrap_data <- sample_n(data, nrow(data), replace = TRUE)


    #fit model on boot data
    model_boot <-  FGR(Hist(time_to_event, status_num) ~  
  median_heart_rate + median_bp_map + median_temp + rr_median + lact_rcs.1 + lact_rcs.2 + wbc_rcs.1 + wbc_rcs.2 + weight + cvl + previousvte + malignancy + surgical_30_days + vasoactives + mech_vent + anticoag_proph_24,
cause = primary_event,
data = bootstrap_data
)
    
    #calculate apparent predictions
  data_prob_vte <- predictRisk(model_full,
  cause = primary_event,
  times = horizon,
  newdata = data
) 
   #calculate bootstrapped predictions
  boot_prob_vte <- predictRisk(model_boot,
  cause = primary_event,
  times = horizon,
  newdata = bootstrap_data
) 
  #calculate bootstrapped predictions
  orig_prob_vte <- predictRisk(model_boot,
  cause = primary_event,
  times = horizon,
  newdata = data
) 
    apparent_cal <- val.prob(data_prob_vte, data$status_dich_14, pl = FALSE)
    #store apparent AUC brier and its standard error
    e50_ap <- unname(quantile(abs(data_prob_vte - approx(lowess(data_prob_vte, data$status_dich_14, iter=0), xout=data_prob_vte, ties=mean)$y), 0.5))
    
    #store bootstrapped AUC brier and its standard error
    boot_cal <- val.prob(boot_prob_vte, bootstrap_data$status_dich_14, pl = FALSE)
    auc_values_boot <- boot_cal[[2]]
    e50_boot <- unname(quantile(abs(boot_prob_vte - approx(lowess(boot_prob_vte, bootstrap_data$status_dich_14, iter=0), xout=boot_prob_vte, ties=mean)$y), 0.5))

    #store original AUC brier and its standard deviation
    orig_cal <- val.prob(orig_prob_vte,data$status_dich_14, pl = FALSE)
    auc_values_original <- orig_cal[[2]]
    e50_orig <- unname(quantile(abs(orig_prob_vte - approx(lowess(orig_prob_vte, data$status_dich_14, iter=0), xout=orig_prob_vte, ties=mean)$y), 0.5))

    #calculate the corrected score
    auc_values_corrected[i] <- apparent_cal[[2]] - abs(auc_values_boot - auc_values_original)
    emax_corrected[i] <- apparent_cal[[14]] + abs(boot_cal[[14]]  - orig_cal[[14]])
    ici_corrected[i] <- apparent_cal[[16]] + abs(boot_cal[[16]]  - orig_cal[[16]])
    e90_corrected[i] <- apparent_cal[[15]] + abs(boot_cal[[15]]  - orig_cal[[15]])
    e50_corrected[i] <- e50_ap + abs(e50_boot - e50_orig)


        #calculate apparent score
    auc_values_apparent[i] <- apparent_cal[[2]] 
    emax_apparent[i] <- apparent_cal[[14]]
    ici_apparent[i] <- apparent_cal[[16]]
    e90_apparent[i] <- apparent_cal[[15]] 
    e50_apparent[i] <- e50_ap
  }
  
  #pooling the results directly in the function
  auc_df <- data.frame(
    auc_apparent = auc_values_apparent,
    emax_apparent = emax_apparent,
    e50_apparent = e50_apparent,
    e90_apparent = e90_apparent,
    ici_apparent = ici_apparent,
    
    auc_corrected = auc_values_corrected,
    emax_corrected = emax_corrected,
    e50_corrected = e50_corrected,
    e90_corrected = e90_corrected,
    ici_corrected = ici_corrected
  )
  
  #summary of results (sd pooled according to cohen 1988 https://www.statisticshowto.com/pooled-standard-deviation/)
  auc_df_summary <- auc_df  %>%
  summarise(
    m_auc_apparent = mean(auc_apparent),
    se_auc_apparent = sd(auc_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    m_auc_corrected = mean(auc_corrected, na.rm = TRUE),
    se_auc_corrected = sd(auc_corrected, na.rm = TRUE)/sqrt(n_bootstrap),
    
    m_e50_apparent = mean(e50_apparent, na.rm = TRUE),
    se_e50_apparent = sd(e50_apparent)/sqrt(n_bootstrap),
    m_e50_corrected = mean(e50_corrected, na.rm = TRUE),
    se_e50_corrected = sd(e50_corrected)/sqrt(n_bootstrap),
    
    m_emax_apparent = mean(emax_apparent, na.rm = TRUE),
    se_emax_apparent = sd(emax_apparent, na.rm = TRUE)/sqrt(n_bootstrap),
    m_emax_corrected = mean(emax_corrected, na.rm = TRUE),
    se_emax_corrected = sd(emax_corrected)/sqrt(n_bootstrap),
    
    m_e90_apparent = mean(e90_apparent, na.rm = TRUE),
    se_e90_apparent = sd(e90_apparent)/sqrt(n_bootstrap),
    m_e90_corrected = mean(e90_corrected, na.rm = TRUE),
    se_e90_corrected = sd(e90_corrected)/sqrt(n_bootstrap),
    
    m_ici_apparent = mean(ici_apparent, na.rm = TRUE),
    se_ici_apparent = sd(ici_apparent)/sqrt(n_bootstrap),
    m_ici_corrected = mean(ici_corrected, na.rm = TRUE),
    se_ici_corrected = sd(ici_corrected)/sqrt(n_bootstrap)
    
  )
  
  return(auc_df_summary)
}
```

**Load data and do MI, and extract one imputed dataset at random**
```{r eval=FALSE}
mimic <- readRDS("analysis subsets/complete_mimic.RDS")

# predictors and outcome
pred <- c("median_heart_rate", "median_bp_map", "median_temp", "rr_median", "lactate", "wbc", "weight", "cvl","previousvte", "malignancy", "surgical_30_days", "vasoactives","mech_vent", "anticoag_proph_24")
outcome <- c("status", "status_num", "time_to_event")

mimic <- mimic %>%
  mutate(rr_median = first_rr_median,
         cvl = as.factor(cvl),
         sex = as.factor(
           case_when(
             sex == "M" ~ 1,
             TRUE ~ 0
           )),
         rr_median = rr_median/5,
         lactate = lactate,
         wbc = wbc/5,
         weight = weight/10,
         median_bp_map = median_bp_map/10,
         median_heart_rate = median_heart_rate/10
         ) %>%
    select(all_of(c("subject_id", outcome, pred))) %>%
    mutate(across(c("malignancy", "cvl", "previousvte", "surgical_30_days", 
                  "mech_vent", "vasoactives", "anticoag_proph_24"),
                ~as.numeric(as.character(.)),
                .names = "{.col}1")
           ) 

number_df <- 10
mimic_imp <- mice(mimic, m=number_df, maxit=30, method = "cart", printFlag = TRUE) 
saveRDS(mimic_imp, file = "analysis subsets/cr_mimic_imp.RDS")
mimic_imp <- readRDS("analysis subsets/cr_mimic_imp.RDS")

random_dataset <- sample(c(1:mimic_imp$m),1)
d <- mice::complete(mimic_imp, random_dataset)

#select data for modeling
d.model <- d[,c("subject_id",pred,outcome)] 
```

**Prep dataset for model building**
```{r eval=FALSE}
primary_event <- 1
horizon <- 14 #set time horizon for prediction (here 14 days)

wbc_rcs <- rcs(d.model$wbc, 3)
colnames(wbc_rcs) <- c("1", "2")
wbc_rcs <- as.matrix(as.data.frame(wbc_rcs))
lact_rcs <- rcs(d.model$lactate, 3)
colnames(lact_rcs) <- c("1", "2")
lact_rcs <- as.matrix(as.data.frame(lact_rcs))
d.model <- cbind(d.model, wbc_rcs, lact_rcs)
d.model <- d.model %>%
  mutate(status_dich_14 = case_when( #setting status based on whether outcome == 1 within 14 days
    status_num == 1 & time_to_event <= 14 ~ 1,
    TRUE ~ 0
  ))
```

**Build model**
```{r eval=FALSE}
fit_fg_final <- FGR(Hist(time_to_event, status_num) ~  
  median_heart_rate + median_bp_map + median_temp + rr_median + lact_rcs.1 + lact_rcs.2 + wbc_rcs.1 + wbc_rcs.2 + weight + cvl + previousvte + malignancy + surgical_30_days + vasoactives + mech_vent + anticoag_proph_24,
cause = primary_event,
data = d.model
)
```

**Perform internal validation**
```{r eval=FALSE}
final_results_internal_validation <- bootstrap_validation_cr(data = d.model, n_bootstrap = 200, model_full = fit_fg_final, primary_event = 1, horizon = 14)


#extract metrics
df_metrics <- pivot_longer(final_results_internal_validation, 
                        cols = -starts_with("se_"), 
                        names_to = "metric", 
                        values_to = "value")

df_metrics$metric <- sub("m_", "", df_metrics$metric)


#extract the se columns into a separate data frame
df_se <- pivot_longer(final_results_internal_validation, 
                      cols = starts_with("se_"), 
                      names_to = "metric_se", 
                      values_to = "se")

#remove 'se_' prefix to match metric names so we can left join them
df_se$metric_se <- sub("se_", "", df_se$metric_se)

#merge the value and se columns by matching metric names
all_metrics_df <- left_join(df_metrics, df_se, by = c("metric" = "metric_se"))

#select columns
all_metrics_df <- all_metrics_df %>% select(metric, value, se)

all_metrics_df <- all_metrics_df %>%
  mutate(
    value = signif(value, digits = 3),
    lower_ci = signif(value - se*1.96, digits = 3),
    upper_ci= signif(value + se*1.96, digits = 3),
     `Value (95% CI)` = paste(value, paste("(", lower_ci, "-",upper_ci, ")", sep = "")))%>%
  select(Metric = metric, `Value (95% CI)` )

apparent_metrics_df <- all_metrics_df %>%
  filter(grepl("apparent", Metric)) %>%
  mutate(Metric = gsub("m_", "", Metric),
    Metric = gsub("_.*", "", Metric)) %>%
  select(Metric, `Apparent value (95% CI)` = `Value (95% CI)`)

corrected_metrics_df <- all_metrics_df %>%
  filter(grepl("corrected", Metric)) %>%
  mutate(Metric = gsub("m_", "", Metric),
    Metric = gsub("_.*", "", Metric)) %>%
  select(Metric, `Corrected value (95% CI)` = `Value (95% CI)`)

printable_internal_validation <- left_join(apparent_metrics_df, corrected_metrics_df, by = "Metric") %>%
  mutate(Metric = case_when(
    Metric == "auc" ~ "C-statistic",
    Metric == "ici" ~ "Integrated Calibration Index",
    Metric == "e50" ~ "E50",
    Metric == "e90" ~ "E90",
    Metric == "emax" ~ "Emax",
    TRUE ~ Metric
  )) %>%
  mutate(Metric = factor(Metric, levels = c("C-statistic", "Integrated Calibration Index",  "E50", "E90", "Emax"))) %>%
  arrange(Metric) %>%
  kbl(format = "html", escape = FALSE) %>%
  kable_classic(full_width = FALSE, html_font = "Times")
```

**Making calibration plot in development set**
```{r eval=FALSE}
#calc probabilities
mimic_prob  <- d.model %>%
  mutate(prob_vte = predictRisk(fit_fg_final,
  cause = primary_event,
  times = horizon,
  newdata = d.model
)[, 1] )

percentile_95 <- quantile(mimic_prob$prob_vte, probs = 0.95)

internal_validation_1 <- ggplot(mimic_prob, aes(x = prob_vte, y = status_dich_14)) +
 geom_smooth(color = "darkblue", method = "loess", se = FALSE, size = 0.5, span = 0.75) + #LOESS smooth line
  stat_smooth(color = "darkred", method="glm", family="binomial", se=F, size = 0.5) +
  geom_vline(xintercept = percentile_95, linetype = "dashed", color = "gray", size = 0.5) + #95th percentile line
  scale_y_continuous(expand = c(0, 0),limits = c(0, 1), breaks = seq(0, 1, by = 0.05)) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 1), breaks = seq(0, 1, by = 0.05)) +
  geom_abline(size = 4, alpha = 0.5, color = "gray") + #adds a line with a slope of 1 and intercept of 0 by default
  xlab("") +
  ylab("Observed Probability") +
  theme_minimal() +
  ggtitle(expression(bold("Figure x.") ~ "Calibration curve of internal validation")) +
  coord_cartesian(xlim = c(0, 0.2), ylim = c(0, 0.2)) +
  theme(plot.title = element_text(hjust = 0.5, family = "Times New Roman", face = "bold"),
        text = element_text(family = "Times New Roman"),
        panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        plot.margin = unit(c(1,1,0,1), "lines"))

internal_validation_2 <- ggplot(mimic_prob, aes(x = prob_vte)) +
  geom_histogram(color = "black", fill = NA, binwidth = 0.001) + 
  scale_x_continuous(limits = c(0, 0.2), breaks = seq(0, 0.2, by = 0.05)) +
  xlab("Predicted Probability") +
  ylab("") +
  theme_minimal() +
  theme(text = element_text(family = "Times New Roman"),
        panel.background = element_rect(fill = "white", colour = NA), #remove border color
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(colour = "white"),
        panel.border = element_blank()) + # add line for x-axis border
  geom_segment(aes(x = 0, y = 0, xend = 0.2, yend = 0), color = "black", size = 0.05) #add manual border for x-axis from x=0 to x=0.35

legend_plot <- ggplot(data.frame(x = c(0, 1), y = c(0, 1)), aes(x, y)) +
  geom_line(aes(color = "Logistic calibration"), size = 0.5) +
  geom_line(aes(color = "Locally estimated scatterplot smoothing"), size = 0.5) +
    geom_line(aes(color = "95% Percentile of Predicted Risks"), size = 0.5, linetype = "dashed") +
  geom_line(size = 10, show.legend = FALSE, color = "white", fill = "white") + #do not show in legend
  scale_color_manual("", 
                     values = c("Logistic calibration" = "darkred", 
                                "Locally estimated scatterplot smoothing" = "darkblue",
                                "95% Percentile of Predicted Risks" = "gray"
                                )) +
  theme(legend.position = "top", 
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        axis.title.x = element_blank(), 
        axis.ticks.x = element_blank(),
        axis.title.y = element_blank(), 
        axis.ticks.y = element_blank(),
        axis.text.x= element_blank(),
        axis.text.y = element_blank(),
        panel.border = element_blank(),
        legend.text = element_text(size = 10, family = "Times New Roman"),
        legend.background = element_rect(fill = "white"),
        legend.key = element_blank())



#combining the adjusted plots
internal_validation_calibration <- arrangeGrob(internal_validation_1, internal_validation_2, legend_plot, 
                             heights = unit(c(3, 1, 0.6), "null"), ncol = 1)
```

**Save R environment**
```{r eval=FALSE}
save.image(file ='cr_model_environment.RData')
```

**Load R environment**
```{r}
load('cr_model_environment.RData')
```

**Summary table for internal validation**
```{r message=FALSE, warning=FALSE}
printable_internal_validation
```

**Calibration in development set**
```{r fig.height=8, fig.width=8}
grid.newpage()
grid.draw(internal_validation_calibration)
```


**Compare own calibration to other packages**
```{r message=FALSE, warning=FALSE}
score_dmodel_internal <- Score(
  list("fg_validation" = fit_fg_final),
  formula = Hist(time_to_event, status_num) ~ 1,
  cens.model = "km",
  data = d.model,
  conf.int = TRUE,
  times = horizon,
  #metrics = c("auc", "brier"),
  summary = c("ipa"),
  cause = primary_event,
  plots = "calibration"
)

calplot_pseudo_internal <- plotCalibration(
  x = score_dmodel_internal,
  brier.in.legend = FALSE,
  auc.in.legend = FALSE,
  cens.method = "pseudo",
  bandwidth = 0.05, # leave as NULL for default choice of smoothing
  cex = 1,
  round = FALSE, # Important, keeps all unique risk estimates rather than rounding
  xlim = c(0, 0.2),
  ylim = c(0, 0.2),
  rug = TRUE,
  xlab = "Predictions",
  bty = "n"
)
title("Calibration plot using pseudo observations internal")
```